#  elasticSearch权威指南
##  索引 index
*   名词--index,类似传统关系数据库的database,描述相关文档的存储位置
    -   索引是一个用来指向一个或者多个分片的逻辑命名空间
    -   一个分片是一个最小级别的工作单元，保存索引所有数据的一部分数据。
    -   一个分片就是一个luncene实例，一个lucene实例就是一个完整的搜索引擎
    -   当扩大或者缩小集群时，自动将节点间的分片迁移，保证集群平衡
*   动词--index,索引一个文档，表示把一个文档存储到index(database)里，以便可以被检索或者查询。
*   倒排索引，传统关系数据为特定列添加一个索引，如b-tree索引，来加速检索
    -   Elasticsearch使用倒排索引（inverted index)的数据结构来完成相应的功能。
    -   默认情况文档中所有字段都有一个倒排索引，这样可以被搜索

##  底层分布式任务：
*   将文档路由到不同的容器中的不同的分片shards中
*   将分片均匀分配到各个节点，多索引和搜索做负载均衡
*   备份每一个分片，防止硬件故障造成数据丢失，高可用
*   将集群中任一节点上的请求路由到响应的数据所在节点
*   增加 或者 删除 节点，分片都可以无缝扩展与迁移

##  文档元数据
*   _index 文档存储的地方
*   _type 文档代表的对象的类
    -   描述一个有相同结果的事物，如，用户，博客，评论
    -   每个type都有自己的映射（mapping)
*   _id 文档的唯一标识

## 文档局部更新 -- update api
*   使用一个请求来实现局部更新，如增加数量
*   文档是不可变的，只能被替换
*   update api =  检索 - 修改 - 重建索引
*   upsert 更新或者插入

## 路由文档到分片
*   文档对应的分片如何确定
    -   shard = hash(id 或者 指定字段) % 总主分片数
    -   主分片数不能改变，因为影响原来分片的位置、

## 主分片和复制分片交互
*   每个节点都有处理能力，请求可以发送给任意节点
*   每个节点都知道文档在哪个节点，可以转发请求到需要的节点

## 搜索search api
*    有两种类型：
    -    简易版 --查询字符串，将所有的参数通过查询字符串定义
    -    结构化查询语句DSL--JSON 表示请求体

## 确切值 Exact value , 全文文本，Full text
*   确切值 Exact value - 一个日期，或者用户Id,一个地址
*   全文文本 -- 非结构化数据
    -   通过文本分析analyzes,使用结果建立一个倒排索引，通过索引计算匹配度，查询


## 倒排索引 -- 快速全文搜索
*   倒排索引由文档中出现的唯一的单词列表，以及单词在文档中的位置组成
*   倒排索引创建
    -   输入--文档文本
        +   the quick brown fox jumped over the lazy dog
    -   文本分词
        +   将文档内容切分成独立的单词（terms or tokens)
    -   排序 -- 将所有独立的单词放入列表并排序
        +   矩阵 = 行为独立的单词，列为所有文档，值为单词是否在文档中出现

##  分析和分析器
*   分析的过程
    -   表征化一个文本块为适用于倒排索引单独的词term 
        +   文档内容 =分词=》 terms
    -   标准化这些词为标准形式，提高可搜索性和查全率
*   分析器analyzer ,完成三个功能：
    -   字符过滤器 character filter,过滤如html标记等无用信息
    -   分词器 tokenizer,将文本切分成独立的单词
        +   简单分词如：空格，逗号分隔
    -   表征过滤 ， token filters,
        +   修改词，如果转换小写，去掉停用词，增加同义词

## 内建分析器
*   标准分析器 -- 默认使用
    -   根据Unicode consortium定义单词边界，
    -   去掉大部分标点，
    -   大写转小写
*   简单分析器
    -   将非单个字幕文本切分，大写转小写
*   空格分析器
    -   空格切分，不转换大小写
*   语言分析器 -- 考虑到语言特性
    -   english --自带英语停用词，词性转换

## 分析器被使用
*   index一个文档，全文字段通过指定的分析器转换为独立的单词terms,创建倒排索引
    -   查询的字符串需要经过同样的分析处理流程，保证词在索引中存在
*   每个字段如何定义：
    -   当查询全文字段full text是，查询将使用相同的分析器来分析查询字符串，产生正确的词列表
    -   当查询一个确切值字段，查询将不分析查询字符串，但是可以自己指定
        +   如一个文档保护date字段值为2018-09-08
            *   当_all 当成全文字段查询时，会被分为2018，09，08三个词
            *   当date字段查询是，因为是date类型，当成一个单独的词，2018-09-08

## 映射
*   索引中每个文档都有一个类型type,每个类型都有自己的映射定义
*   一个映射定义 了字段类型，每个字段的数据类型，以及字段被Es处理的方式
*   主要字段类型：
    -   String : string
    -   Whole number : byte, short,interger,long
    -   Floating point:float,double
    -   Boolean : boolean
    -   Date :date
*   定义string 类型字段是可以指定 index 时的处理方式
    -   analyzed： 表示该字段会通过指定的分析器分析成terms,然后查询
    -   not_analyzed ： 表示该字段 不会被分词，当成整个单词，搜索
    -   no: 不索引整个字段，不能被搜索

## 结构化过滤 Filter DSL
*   一条过滤语句会询问每个文档的字段值是否包含特定的值：
    -   是否created 的日期范围在 2014 到 2015
    -   是否status字段包含单词“published"

##  结构化查询 query DSL
*   一条查询语句会询问每个文档的字段值与特定值的匹配程度：
    -   查找与 full text search 这个词的最佳匹配文档
    -   查找与单词run 相匹配的文档，如包含runs,runing,jop等的文档
    -   匹配分词与文档的相关程度
    -   每次查询会给出一个相关性评分_score

## filter DSL vs queryDSL
*   使用过滤语句得到一个结果集---一个简单文档列表，快速匹配运算并存入内存
*   查询语句不仅要查到匹配的文档，还要计算每个文档相关性，更耗时，结果也不可缓存
*   通过倒排索引，一个只匹配少量文档的简单查询语句在百万级文档中查询效率与一条经过缓存的过滤语句相当
*   过滤语句就是缩小匹配文档结果集

## 相关性
*   ES相似度计算为TF/IDF，索引频率/反向稳定频率
*   检索词频率：
    -   检索词在该字段出现的频率，越高越相关 ，某个文档的某个字段出现频率
*   反向文档频率：
    -   每个检索词在索引（文档)中出现的频率，越高，越不相关，所有文档中出现的频率
*   字段的长度越长，相关性越低，如title 中出现的词，比content出现的词相关性大

## 深分页--爬虫，奔溃


## 搜索选项
*  preference  -- 控制使用哪个分片或者节点处理搜索请求
    -  _primary, _primary_first, _local 
*   结果震荡
    -   相同的timestamp排序，在不同的分片中顺序不一致，刷新可能结果发生变化
    -   解决方法
        +   对于同一个用户使用同一分片

##  lucene 处理文档
*   lucene 中，一个文档由一组简单的键值对组成，一个字段至少要一个值，可以有多个值
*   一个单独的字符串可能在分析过程中转换成多个值
*   当在lucene中索引一个文档时，每个字段的值都被加到相关字段的倒排索引中

##  lucene 类型的实现
*   一个索引可能包含多个类型，每个类型有各自的映射和文档
*   每个文档的类型名称被存储在_type的元数据字段上，通过_type字段过滤特定的类型的文档
*   lucene 没有映射的概念，映射是ES将复杂JSON文档映射成lucene需要的扁平化的数据的方式

##  元数据 _source 字段
*   json字符串表示的文档主题保存在_source字段中，在写入硬盘前压缩
*   存储_source 字段占用硬盘空间

##  元数据 _all 字段
*   一个所有其他字段值的特殊字符串字段
*   新应用探索阶段使用，使用全部字段
*   include_in_all 控制某个字段是否要在_all中
*   _all字段只是一个经过分析的string字段，使用默认的分析器分析，不管值本来指定的分析器，也可以单独指定_all字段的分析器



